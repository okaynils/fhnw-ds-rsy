{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems - Mini Challenge FS24\n",
    "\n",
    "In this minichallenge we will explore a MovieLens dataset and implement several recommender systems and evaluation methods. Subsequently we will optimize these methods and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission deadline:** 5.5.2024 23:59. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines for Implementation and Submission\n",
    "- Code must be written in Python or R. The versions of all used packages must be given for reproducability.\n",
    "- We develop numerous algorithms ourselves. Unless explicitly stated otherwise, only the following libraries may be used in Python: numpy, matplotlib, seaborn, pandas. In R only the base package, ggplot2, lattice, dplyr. \n",
    "- Follow good coding practices and write modular, reusable code.\n",
    "- The submitted solution must contain all codes and the results. No code may be outsourced.\n",
    "- If computation time is too long for productive prototyping and debugging work, it is recommended to reduce the dataset to a fraction of its original. However, final results should be calculated on the full dataset. \n",
    "- All plots must be fully labeled (title, axes, labels, colorbar, etc.) so that the plot can be easily understood.\n",
    "- Each plot should be accompanied by a brief discussion, which explains the plot and captures the key insights that become visible.\n",
    "- Only fully labeled plots with an accompanying discussion will be assessed.\n",
    "- The last commit in your fork of the repo before the submission deadline counts as the submission.\n",
    "- If you would like to submit and have the mini-challenge assessed, please send a short email to the subject expert (moritz.kirschmann@fhnw.ch) within 2 days after submission.\n",
    "- Please do not delete, duplicate, or move the existing cells. This leads to problems during the correction. However, you may add as many additional cells as you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - A deep exploration of the dataset (17 points)\n",
    "We will work with a subset of the MovieLens dataset. This subset is located under ``data/ml-latest-small``. Read the ``README.txt``carefully. \n",
    "Open the files. \n",
    "Create usefull data representations such as the the *User Item Matrix*.\n",
    "Perform explorative data analysis. Describe the available data. Did you find duplicates or otherwise bad data? \n",
    "\n",
    "Generate lists of\n",
    "- Top 20 movies by average rating\n",
    "- Top 20 movies by number of views\n",
    "\n",
    "Answer: \n",
    "- What is the range of the ratings? \n",
    "- Which genre has be rated how many times?\n",
    "- How sparse is the User Rating Matrix?\n",
    "\n",
    "Plot the following:\n",
    "- How many users have rated how many movies\n",
    "- Which rating is given how often on average\n",
    "- Which rating is given how often on average per genre\n",
    "- The rating distributions of 10 random movies\n",
    "- The rating distributions of 3 movies that you have watched\n",
    "- How many users give which average rating\n",
    "- How often a movie was rated as a function of average rating\n",
    "- A heatmap of the User Item Matrix\n",
    "- A heatmap of the User Item Matrix for the 100 most rated movies for the 50 users with most ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Building a baseline RS (7 points)\n",
    "In this exercise we will build a baseline RS and functions to calculate fundamental performance metrics. \n",
    "\n",
    "Build the following baseline RS to predict Top-N (default N=20):\n",
    "1. In reference to the book *Collaborative Filtering Recommender Systems by Michael D. Ekstrand, John T. Riedl and Joseph A. Konstan* (p. 91ff) implement the baseline predictor $$ b_{u,i}= \\mu +b_u +b_i $$ with the regularized user and item average offsets: $$ b_u = \\frac{1}{|I_u| + \\beta_u} \\sum_{i \\in I_u} (r_{u,i} - \\mu) $$ and $$ b_i = \\frac{1}{|U_i| + \\beta_i} \\sum_{u \\in U_i} (r_{u,i} - b_u - \\mu) . $$ Build a recommender system upon this baseline predictor. Set the default damping factors $\\beta_u$ and $\\beta_i$ both to 20.\n",
    "2. Build a RS that recommends based on *random* recommendations.  \n",
    "\n",
    "Output the recommendations for three example users of your choice. Can you find a user that represents your taste? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Evaluation methods (8 points)\n",
    "\n",
    "Implement a function to partition your dataset for an offline evaluation based on holding out of random users with 5x cross validation. *Use this for all further exercises*\n",
    "Explain your considerations.\n",
    "\n",
    "Implement functions to calculate the following metrics:\n",
    "- *Mean Absolute Error (MAE)* \n",
    "- *Root Mean Square Error (RMSE)*\n",
    "- *Precision@N* with default $N=15$ and relevance threshold 3.5 stars.\n",
    "- *Recall@N* with default $N=15$ and relevance threshold 3.5 stars.\n",
    "\n",
    "Explain each of these.\n",
    "\n",
    "Note: For the last two see https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Optimize hyperparameters of baseline RS (4 points)\n",
    "Optimize the hyperparameters $\\beta_u$ and $\\beta_i$ for the baseline RS from exercise 2 using the RMSE metric. You can use the `GridSearchCV` class from scikit-learn to perform the grid search. To save computation time find a reasonable maximum value for the betas. Explain your approach and your solution.\n",
    "Plot the RMSE as a function of the betas and output all metrics implemented in exercise 3 achieved at the best RMSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Collaborative filtering item based and user based (10 points)\n",
    "In this exersise we will build several different collaborative-filtering RS based on nearest neighbour technique, both in terms of item and user. \n",
    "\n",
    "Implement:\n",
    "1. a RS based on the $K$ most similar items (K nearest neighbours). Similarity shall be calculated based on *cosine similarity*. \n",
    "2. a RS based on the $K$ most similar items (K nearest neighbours). Similarity shall be calculated based on *Pearson Correlation Coefficienct*. \n",
    "3. a RS based on the $K$ most similar users (K nearest neighbours). Similarity shall be calculated based on *cosine similarity*. \n",
    "4. a RS based on the $K$ most similar users (K nearest neighbours). Similarity shall be calculated based on *Pearson Correlation Coefficienct*. \n",
    "\n",
    "Each should have a default $K$ of 30.\n",
    "\n",
    "Describe the two similarity metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 6 - Optimize hyperparameter $K$ (6 points)\n",
    "Optimize the hyperparameter $K$ for all RS from the prior exercise optimizing for minimal RMSE. \n",
    "For each RS plot RMSE, Precision@N and Recall@N as a function of $K$. \n",
    "\n",
    "Compare the results of these four RS on the 3 example users. Do the results match your expectation? Describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 7 - Model-based RS: SVD (6 points)\n",
    "In this exercise we will use the unsupervised method *singular value decomposition (SVD)* from the python package *surprise* (https://surpriselib.com, documentation https://surprise.readthedocs.io/en/stable/matrix_factorization.html) or the R package *recommenderlab*. SVD can compress much of the information of a matrix in few components.  \n",
    "\n",
    "Run the SVD RS and show the results on the three example users from exercise 2. Explain how this algorithm works.\n",
    "\n",
    "Note: A very good general introduction to SVD is this youtube video series starting with https://www.youtube.com/watch?v=gXbThCXjZFM&t=337s . See *Collaborative filtering recommender systems* by Ekstrand et al. *Mining of massive datasets* by Leskovec, Kapitel 11 (2020) and ,*Recommender systems: The textbook*, by Aggarwal, chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 - Optimize hyperparameter $k$ or `n_factors` (4 points)\n",
    "Optimize the hyperparameter, representing the number of greatest SVD components used for the truncated reconstruction of the user item matrix, to minimize RMSE.\n",
    "Plot RMSE, Precision@N and Recall@N as a function of this hyperparameter. Finally output all performance metrics from exercise 3 for the found value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9 - Everything goes (30 points)\n",
    "In this exercise you can explore different methods of RS. You are not limited what methods you apply. You can try to improve the methods from the earlier exercises by adjusting them or generating ensemble or hybrid RS. Also you can train deep neural networks, use NLP methods, use the available links to imdb available in the dataset to further enrich the dataset or find an obscure method by someone else on Github. However document what your inspirations and sources are and your process. Important: If you use the work of someone else you must be able to explain the method conceptually. \n",
    "Output the performance metrics of exercise 3.\n",
    "\n",
    "**Build and optimize at least three different methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10 - Compare all RS that you build in this challenge (6 points)\n",
    "Compile a table with the performance metrics of exercise 3 for all RS from this MC (Make sure to include also the baseline RS). Also generate comparative plots. Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11 - Risks of RS on user or society (5 points)\n",
    "In this exercise we take one step back from the technical aspects of RS.\n",
    "Positive effects of good recommendations are easy to imagine: Happy customers and successful companies. However  also come with potential risks. Which risks for the user or society can you imagine or discover online? Pick one risk and describe what you would do to mitigate this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the Guidelines for Implementation and Submission one more time.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RSY_FS24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
